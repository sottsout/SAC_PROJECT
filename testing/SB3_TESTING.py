"""
2-phase SAC training ÏƒÎµ PandaReachDense-v3 ÎºÎ±Î¹ PandaPickAndPlaceJoints-v3
Ï‡Ï‰ÏÎ¯Ï‚ ÎºÎ±Ï„Î±Î³ÏÎ±Ï†Î® Î²Î¯Î½Ï„ÎµÎ¿
"""

import os
from pathlib import Path

import gymnasium as gym
import panda_gym  # noqa: F401  (Î±Ï€Î»ÏÏ‚ Î³Î¹Î± Î½Î± ÎµÎ³Î³ÏÎ±Ï†Î¿ÏÎ½ Ï„Î± envs)
from stable_baselines3 import SAC
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.evaluation import evaluate_policy

# ---------------------------------------------------------------
# Paths & params
# ---------------------------------------------------------------
REACH_STEPS = 30_000
PICKPLACE_STEPS = 800_000
MODEL_DIR = Path("models/sac")

MODEL_DIR.mkdir(parents=True, exist_ok=True)

print("âœ… Starting 2-phase SAC training (NO video recording)")
print("ğŸ“ Models will be saved to:", MODEL_DIR.resolve())

# ---------------------------------------------------------------
# Helper: Train SB3 Agent
# ---------------------------------------------------------------
def train_sb3_agent(env, agent, total_timesteps: int, name: str):
    agent.learn(total_timesteps=total_timesteps, log_interval=10)

    agent.save(MODEL_DIR / name)
    mean_r, std_r = evaluate_policy(agent, env, n_eval_episodes=10)
    print(f"ğŸ“Š {name} | Mean reward: {mean_r:.2f} Â± {std_r:.2f}")

# ---------------------------------------------------------------
# Phase 1 â€“ PandaReachDense-v3
# ---------------------------------------------------------------
print("\nâ€” Phase 1: PandaReachDense-v3 â€”")

reach_env = Monitor(
    gym.make(
        "PandaReachDense-v3",
        reward_type="dense",
        render_mode="human",  # GUI Î³Î¹Î± Î¿Ï€Ï„Î¹ÎºÎ® ÎµÏ€Î¹Î²ÎµÎ²Î±Î¯Ï‰ÏƒÎ· (Ï‡Ï‰ÏÎ¯Ï‚ video)
    )
)

sac_reach = SAC("MultiInputPolicy", reach_env, verbose=1)
train_sb3_agent(reach_env, sac_reach, REACH_STEPS, "sac_reach")

# ÎšÎ»ÎµÎ¯ÏƒÎµ Ï„Î¿ env Î³Î¹Î± Î½Î± ÎµÎ»ÎµÏ…Î¸ÎµÏÏ‰Î¸ÎµÎ¯ Ï„Î¿ PyBullet GUI Ï€ÏÎ¹Î½ Î±Î½Î¿Î¯Î¾ÎµÎ¹Ï‚ Î¬Î»Î»Î¿
reach_env.close()

# ---------------------------------------------------------------
# Phase 2 â€“ PandaPickAndPlaceJoints-v3
# ---------------------------------------------------------------
print("\nâ€” Phase 2: PandaPickAndPlaceJoints-v3 â€”")

pick_env = Monitor(
    gym.make(
        "PandaPickAndPlaceJoints-v3",
        control_type="joints",
        reward_type="dense",
        render_mode="human",   # ÎºÎ±Î¹ ÎµÎ´Ï GUI, Î±ÎºÏŒÎ¼Î· ÎºÎ±Î¼Î¹Î¬ ÎºÎ±Ï„Î±Î³ÏÎ±Ï†Î®
    )
)

sac_pick = SAC("MultiInputPolicy", pick_env, verbose=1)
train_sb3_agent(pick_env, sac_pick, PICKPLACE_STEPS, "sac_pickplace")

pick_env.close()

print("\nâœ… Training complete.")
print("ğŸ“ Trained models stored in:", MODEL_DIR.resolve())
